{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3916cd0d-c4c6-431a-a41c-75bb59335f72",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "Herein we explore the generalized method of moments (GMM) using automatic differentiation (AD).  GMM is a likelihood-free way of estimating population parameters.  AD is kind of like symbolic differentiation; it is software that can create the gradient of an expression and evaluate it. \n",
    "\n",
    "We will be using the moment generating function (MGF) and cumulant generating function below, so it is useful to briefly review those now.  The MGF is defined as\n",
    "\n",
    "$$\n",
    "M(t) = \\mathbb{E}[e^{t X}]\n",
    "$$\n",
    "\n",
    "and has the property $\\mathbb{E}[X^k] = M^{(k)}(0)$ under certain regularity conditions.  The CGF is $K(t) = \\log M(t)$, which has the nice property that $K'(0)$ is the mean and $K''(0)$ is the variance, i.e. the centered second moment, amongst other things.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06af1db-f0f8-4bbb-8ea1-4ef26772b348",
   "metadata": {},
   "source": [
    "# Automatic differentiation\n",
    "\n",
    "We will use [Jax](https://jax.readthedocs.io/en/latest/index.html) for automatic differentiation (AD).  It is straightforward to use.  Below, we define the moment generating function and cumulant generating function of a normal distribution with mean and standard deviation $\\theta = (\\mu, \\sigma)$.\n",
    "\n",
    "We can then compute the gradient of these functions using `grad`.  The `grad` function will take the gradient of the first argument by default, but it is possible to specifiy which argument you want to differentiate.\n",
    "\n",
    "We compute the first and second centered moment using the CGF and then evaluate those for a given $(\\mu, \\sigma)$ to confirm that this indeed is working as intended.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f27e9fde-53a0-4266-8173-6df06a333033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4f57453-984d-41bc-a62e-54476cf3dcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mgf_norm(t, theta):\n",
    "    return jnp.exp(t * theta[0] + 0.5 * jnp.square(theta[1] * t))\n",
    "\n",
    "def cgf_norm(t, theta):\n",
    "    return t * theta[0] + 0.5 * jnp.square(theta[1] * t)\n",
    "\n",
    "cgf1 = grad(cgf_norm)\n",
    "cgf2 = grad(grad(cgf_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54c8740f-b405-46e6-9d3c-7fff981d11aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(1.5, dtype=float32, weak_type=True),\n",
       " Array(4., dtype=float32, weak_type=True))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta0 = jnp.array([1.5, 2.0])\n",
    "cgf1(0.0, theta0), cgf2(0.0, theta0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d616f0-b167-4ce3-8670-53001f630f25",
   "metadata": {},
   "source": [
    "# GMM for population parameter estimation\n",
    "\n",
    "[Eric Zivot](https://faculty.washington.edu/ezivot) has an accessible [summary](https://faculty.washington.edu/ezivot/econ583/gmm.pdf) of GMM.  We recapitulate the essential parts here.\n",
    "\n",
    "The idea is the following: you have $i = 1, \\ldots, K$ functions, or moment conditions, that satisfy \n",
    "\n",
    "$$\n",
    "\\mathbb{E}[g_i(X; \\theta)] = 0, i = 1, \\ldots, K\n",
    "$$\n",
    "\n",
    "when $\\theta = \\theta_0$, the true value for the population.  (We will use capital letters like $X$ to denote a random variable and lower case letters like $x$ to denote a realization from the random variables distribution.)\n",
    "\n",
    "The sample equivalent of this is\n",
    "\n",
    "$$\n",
    "\\bar g_i(\\theta) = \\frac{1}{n} \\sum_{t=1}^{n} g_i(x_t, \\theta) = 0.\n",
    "$$\n",
    "\n",
    "Because we may have more moment conditions than parameters, we may not be able to solve this exactly using sampled data.  An obvious thing to do is to  minmize the squared error of these sample moment conditions.  Because it will be useful later, we actually want to think about minimizing the squared error using a symmetric, positive definite weighting matrix $W$.  That is, we want to minimize\n",
    "\n",
    "$$\n",
    "J_n(\\theta, W) = n \\bar g' W \\bar g.\n",
    "$$\n",
    "\n",
    "The choice of $W$ can have a dramatic effect on the efficiency of the estimator, but, for any choice of $W$, solving for the $\\theta$ that minimizes $J_n$ will produce a consistent estimate as $n \\rightarrow \\infty$.  The most efficient estimator is when $W$ is the inverse of the asymptotic variance of $\\bar g$ as our data grows without bound, i.e. $n \\rightarrow \\infty$, under the true value $\\theta = \\theta_0$.  Assuming we have IID data,\n",
    "\n",
    "$$\n",
    "Var[ \\frac{1}{n} \\sum_{t=1}^{n} g(X_t, \\theta) ] = \\frac{1}{n} Var[ g(X_1, \\theta) ].\n",
    "$$\n",
    "\n",
    "Let $\\hat S$ be an estimator of the variance term,\n",
    "\n",
    "$$\n",
    "\\hat S(\\theta) = V_n(\\theta) = \\frac{1}{n} \\sum_{i=1}^{n} g(x_i, \\theta) g(x_i, \\theta)'\n",
    "$$\n",
    "\n",
    "and let $\\hat W = \\hat S^{-1}$.  Then we can iteratively cylce through values of $\\hat \\theta$ and $\\hat S$ by:\n",
    "\n",
    "$$\n",
    "\\hat \\theta = \\underset{\\theta}{\\text{argmin}} \\; J_n(\\theta, \\hat S)\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\hat S = V_n(\\hat \\theta)\n",
    "$$\n",
    "\n",
    "to arrive at the estimator $\\hat \\theta$ that arises using the optimal weight matrix, approximately speaking.\n",
    "\n",
    "Lastly, and critically, when we have $K$ moment conditions and only $L$ parameters, then asymptotically, $J_n$ converges to a $\\chi^2_{K-L}$ distribution under the null hypothesis.  Thus, we can use $J_n$ as a statistic to create a p-value:\n",
    "\n",
    "$$\n",
    "p = 1 - CDF_{\\chi^2}(J_n(\\hat \\theta, \\hat S), \\; df=K - L).\n",
    "$$\n",
    "\n",
    "\n",
    "# Moment conditions for estimating population parameters\n",
    "\n",
    "For our purposes here, we adopt the moment conditions\n",
    "\n",
    "$$\n",
    "g_i(x, \\theta) = x^i - M_\\theta^{(i)}(0), i = 1, \\ldots, 4.\n",
    "$$\n",
    "\n",
    "where $M^{(i)}$ is the $i$th derivative of the moment generating function with respect to $t$ and $\\theta$ is the parameter vector.  AD makes computing $M^{(i)}$ trivial.\n",
    "\n",
    "The code is very simple and can be found [here](https://github.com/jwindle/gmmfun).  We put that code to use below.  It is always useful to have an alternative approach that provides similar results as a way to check one's code, and to that end we also use the cumulant generating function to come up with moment conditions that can be used to find $\\hat \\theta$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db864563-cb18-4635-94eb-b012df02cd49",
   "metadata": {},
   "source": [
    "## Normal example\n",
    "\n",
    "To give you an idea of how this works, let's estimate population parameters and the J-statistic when the null is true.  We use the classes `GmmMgf` and `GmmCgf` to estimate the population parameter using the GMM.  We have to provide the moment generating function (or cumulant generating function) and the bounds on the parameters, which in this case are the mean and standard deviation $\\theta = (\\mu, \\sigma)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d429e7b-0f4f-4f6e-8c55-07fc2690f619",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gmmfun import GmmMgf4, GmmCgf4\n",
    "from gmmfun.utils import sample_moments\n",
    "from scipy.stats import norm, gamma, t, chi2, describe\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83fe8701-c7fb-4d25-925a-8e4a980d5eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "np.random.seed(12345)\n",
    "theta0 = jnp.array([2.0, 1.0])\n",
    "x = norm.rvs(loc=theta0[0], scale=theta0[1], size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd1f4d49-f563-4011-bfac-dd48314b9a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.033614388208864, 1.0350846417161685)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(x), np.std(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c15484f-63e8-4336-8c98-ab5d44ed4dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bounds = jnp.array([-jnp.inf, 0.0])\n",
    "upper_bounds = jnp.array([ jnp.inf, jnp.inf])\n",
    "bounds_norm = (lower_bounds, upper_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e688ce60-6200-4a2a-a749-ca15a868d4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgf_4 = GmmMgf4(mgf_norm, bounds_norm)\n",
    "cgf_4 = GmmCgf4(cgf_norm, bounds_norm)\n",
    "mgf_4.set_data(x)\n",
    "cgf_4.set_data(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77cd937-b379-4b7d-a25e-82cd673244e0",
   "metadata": {},
   "source": [
    "We initialize $\\theta$ to the sample versions of the parameters and then initialize GMM using $I = W$.  You can see that the results are not identical, in terms of either $\\theta$ or $J$, which is not surprising, since we, in effect, have two different $J$ functions at play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8c34082-ab0a-49f1-8f7e-f74a133408cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([2.0198934, 1.0553135], dtype=float32),\n",
       " Array([2.0428522, 1.051978 ], dtype=float32))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_init = jnp.array([jnp.mean(x), jnp.std(x)])\n",
    "mgf_4.opt_I(theta_init).params, cgf_4.opt_I(theta_init).params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2961af7-0a1c-47c2-8075-b987817958af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9761345042539102, 0.9343752883331854)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mgf_4.pval, cgf_4.pval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8504b912-3806-4f30-9f63-522f0ea0d134",
   "metadata": {},
   "source": [
    "We can then update $W$ as suggested above and then update $\\theta$.  And following that, we update both multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c90488e4-69da-4aba-88f7-4f548f0e51b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 47.258965  , -40.763363  ,  12.118055  ,  -1.150733  ],\n",
       "       [-40.763355  ,  43.60277   , -14.460949  ,   1.4693025 ],\n",
       "       [ 12.118056  , -14.460948  ,   5.068251  ,  -0.5336622 ],\n",
       "       [ -1.1507338 ,   1.4693025 ,  -0.5336622 ,   0.05765441]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mgf_4.update_W()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd29efd3-9fab-4ac7-889e-f14056f86095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.7704406 , -0.60642123, -0.5895131 ,  0.13728549],\n",
       "       [-0.6064213 ,  2.6526172 ,  0.31469318, -0.35729185],\n",
       "       [-0.58951306,  0.31469318,  0.19634886, -0.06248762],\n",
       "       [ 0.13728549, -0.35729185, -0.06248762,  0.05759786]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cgf_4.update_W()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22a9e8e6-40b2-4d8d-97f8-a63be474e2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = mgf_4.update_theta() # this returns the output of the optimization\n",
    "foo = cgf_4.update_theta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cd30a73-39dc-455b-8930-b5e5b1942275",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_mgf_4 = mgf_4.update_both(5)\n",
    "trace_cgf_4 = cgf_4.update_both(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cea32ab-b078-489c-9751-a9e6229a2f69",
   "metadata": {},
   "source": [
    "After updating both several times, we see that $\\hat \\theta$ and the $J$-stat are close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db460473-d4d1-475b-b52e-57d76663ad08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([2.0200768, 1.0357895], dtype=float32),\n",
       " Array([2.0214884, 1.035739 ], dtype=float32))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mgf_4.theta, cgf_4.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c10dd3b-833d-4649-b3f4-8bdab14f874e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8933808504104637, 0.8933015652026227)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mgf_4.pval, cgf_4.pval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f154d0fb-4985-4557-82c4-f0ec4a165980",
   "metadata": {},
   "source": [
    "## Gamma Example\n",
    "\n",
    "To convince ourselves, that this was not a fluke, let us repeat the exercise using a gamma distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "460a49c5-6e1b-48a5-9641-8c183efae315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mgf_gamma(t, theta):\n",
    "    return (1 - theta[1] * t)**(-theta[0])\n",
    "\n",
    "def cgf_gamma(t, theta):\n",
    "    return -theta[0] * jnp.log(1 - theta[1] * t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cde461e-d2f1-435f-93cc-f045ae6c3c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 200\n",
    "# np.random.seed(12348)\n",
    "theta0 = jnp.array([5.0, 2.0])\n",
    "x = gamma.rvs(theta0[0], scale=theta0[1], size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3ed2a29-b3d1-4370-9485-27f89c81805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape, scale parameterization\n",
    "lower_bounds = jnp.array([0.0, 0.0])\n",
    "upper_bounds = jnp.array([ jnp.inf, jnp.inf])\n",
    "bounds_gamma = (lower_bounds, upper_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d13650e1-e682-4010-a24e-3cee5b48c47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgf_4 = GmmMgf4(mgf_gamma, bounds_gamma)\n",
    "cgf_4 = GmmCgf4(cgf_gamma, bounds_gamma)\n",
    "mgf_4.set_data(x)\n",
    "cgf_4.set_data(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0a8ab17-e7e8-45c3-9b29-e59bf2a90d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([2.9702945, 3.2302544], dtype=float32),\n",
       " Array([3.1960227, 3.1341908], dtype=float32))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_gamma, sig2_gamma = jnp.mean(x), jnp.var(x)\n",
    "theta_init = jnp.array([mu_gamma**2 / sig2_gamma, sig2_gamma / mu_gamma])\n",
    "mgf_4.opt_I(theta_init).params, cgf_4.opt_I(theta_init).params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "772e89e9-cb51-4704-97dc-1b2355ec75cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mgf_4.pval, cgf_4.pval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fbef4a-7905-4480-a61b-fb45a982af7f",
   "metadata": {},
   "source": [
    "The one issue that arises here is that we can encounter issues of poor conditioning.  This is not surprising, since the size of the moments we are working with can vary greatly.  The old rule of thumb is that a condition number below 1e-15 is a very bad sign for double precision, but we aren't quite to that point yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f95564f9-328a-42ed-88ec-976f91c94a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jwindle/Repos/gmmfun/src/gmmfun/gmm_base.py:110: LinAlgWarning: Ill-conditioned matrix (rcond=2.20426e-09): result may not be accurate.\n",
      "  self.W = sp.linalg.solve(S, self.I, assume_a = \"pos\")\n",
      "/Users/jwindle/Repos/gmmfun/src/gmmfun/gmm_base.py:110: LinAlgWarning: Ill-conditioned matrix (rcond=2.19965e-09): result may not be accurate.\n",
      "  self.W = sp.linalg.solve(S, self.I, assume_a = \"pos\")\n",
      "/Users/jwindle/Repos/gmmfun/src/gmmfun/gmm_base.py:110: LinAlgWarning: Ill-conditioned matrix (rcond=2.19909e-09): result may not be accurate.\n",
      "  self.W = sp.linalg.solve(S, self.I, assume_a = \"pos\")\n"
     ]
    }
   ],
   "source": [
    "trace_cgf_4 = cgf_4.update_both(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0fcfc34-404d-48e9-8e29-9ffd24411685",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jwindle/Repos/gmmfun/src/gmmfun/gmm_base.py:110: LinAlgWarning: Ill-conditioned matrix (rcond=1.7762e-12): result may not be accurate.\n",
      "  self.W = sp.linalg.solve(S, self.I, assume_a = \"pos\")\n",
      "/Users/jwindle/Repos/gmmfun/src/gmmfun/gmm_base.py:110: LinAlgWarning: Ill-conditioned matrix (rcond=1.54893e-12): result may not be accurate.\n",
      "  self.W = sp.linalg.solve(S, self.I, assume_a = \"pos\")\n",
      "/Users/jwindle/Repos/gmmfun/src/gmmfun/gmm_base.py:110: LinAlgWarning: Ill-conditioned matrix (rcond=1.54814e-12): result may not be accurate.\n",
      "  self.W = sp.linalg.solve(S, self.I, assume_a = \"pos\")\n"
     ]
    }
   ],
   "source": [
    "trace_mgf_4 = mgf_4.update_both(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13318090-a555-4ca4-8979-29921dfad717",
   "metadata": {},
   "source": [
    "You can see by just looking at the diagonal that the estimated variances are quite different in scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dde0d292-ef23-4c4a-ae28-33d1124b8c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.8355595e-01, 3.4637293e-03, 9.2738504e-05, 7.9921627e-08],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(cgf_4.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fed1582d-2bab-4d07-8f1c-cb4616283c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.0749578e+01, 2.4691960e-01, 4.3659454e-04, 7.9902030e-08],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(mgf_4.W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c501a93-fbe0-41b8-b743-08b06f8c791b",
   "metadata": {},
   "source": [
    "But ultimately it seems that the computations are ok since we end up with similar values for both approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22060108-ea74-44e1-bdb8-5ba8082ef765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([4.714462, 2.132177], dtype=float32),\n",
       " Array([4.7109103, 2.1361232], dtype=float32))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cgf_4.theta, mgf_4.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a7460fc-a225-46cf-bf1c-96ad31cf1523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4682780481912052, 0.46859687863293076)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cgf_4.pval, mgf_4.pval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0edbab-3984-4255-aa2a-dec2edb54ad1",
   "metadata": {},
   "source": [
    "## Scaling the moments for better numerical stability\n",
    "\n",
    "One option for improving the numerical stability is to change the moment functions slightly, by re-scaling the higher moments.  When we do that, at least in our numerical experiments, we alleviate the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed288ee8-0df4-4336-8f7e-8d4b34ea740a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([3.199155 , 3.0612576], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gmmfun import GmmMgf\n",
    "\n",
    "discounts = np.array([10**k for k in range(1, 5)])\n",
    "mgf_arb = GmmMgf(mgf_gamma, bounds_gamma, 4, weights=1.0/discounts)\n",
    "mgf_arb.set_data(x)\n",
    "mgf_arb.opt_I(theta_init).params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5910eaaa-8796-4dc4-9094-74977be62a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([4.7079067, 2.136882 ], dtype=float32), 0.46879198620433815)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mgf_arb.update_both(5)\n",
    "mgf_arb.theta, mgf_arb.pval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531e65f8-d607-413b-b878-691c2b046aed",
   "metadata": {},
   "source": [
    "Here we can see that the variance components for the scaled moment conditions are more similar in scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f7b6504-ad48-45fb-8452-09430f1fedee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2071.2688   , 2464.7502   ,  435.82693  ,    7.9766316],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(mgf_arb.W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1de851-b06b-4b3d-abb1-76e1960041db",
   "metadata": {},
   "source": [
    "## Arbitrary number of moments\n",
    "\n",
    "Lastly, we have snuck in a new class here, `GmmMgf`.  This class works for an arbitrary number of moments, though as you increase the number of moments, you encounter the stability issues mentioned above.  The results are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f69f11f1-5aae-4fb7-a202-dc96452a6bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([3.6667109, 2.7302873], dtype=float32), 0.8764779461175797)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_moments = 3\n",
    "discounts = np.array([10**k for k in range(1, n_moments + 1)])\n",
    "mgf_arb = GmmMgf(mgf_gamma, bounds_gamma, n_moments, weights=1.0/discounts)\n",
    "mgf_arb.set_data(x)\n",
    "mgf_arb.opt_I(theta_init).params, mgf_arb.pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e9bb393-4267-4102-9c15-3323c26f3d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Array([4.645163, 2.149645], dtype=float32),\n",
       " Array([4.6497984, 2.147479 ], dtype=float32),\n",
       " Array([4.6497984, 2.147479 ], dtype=float32),\n",
       " Array([4.6497984, 2.147479 ], dtype=float32),\n",
       " Array([4.6497984, 2.147479 ], dtype=float32)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_mgf_arb = mgf_arb.update_both(5)\n",
    "[out.params for out in trace_mgf_arb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4c2f89b-f12e-4f56-81ee-40201d4db2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3554125616864303"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mgf_arb.pval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4da11e9-9aae-41f8-a928-e39c6ba0a361",
   "metadata": {},
   "source": [
    "## Testing the alternative\n",
    "\n",
    "Everything above was for testing when the null is true.  What happens when we use the gamma data, but fit it to a normal moment generating function?  We get a strong rejection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36f9a9b1-4ea5-4da5-93cf-05dd150fd83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([8.980362 , 7.0330486], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discounts = np.array([10**k for k in range(1, 5)])\n",
    "mgf_arb = GmmMgf(mgf_norm, bounds_norm, 4, weights=1.0/discounts)\n",
    "mgf_arb.set_data(x)\n",
    "mgf_arb.opt_I(theta_init).params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29bedc2d-7ca7-41a5-8a5e-4b330b30fd4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([9.099801, 3.288657], dtype=float32), 3.0196674971394444e-05)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mgf_arb.update_both(5)\n",
    "mgf_arb.theta, mgf_arb.pval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c54a109-ef62-416b-836a-889a378db54b",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "The underlying code here is very minimal.  Using the power of automatic differentiation and the elegance of GMM, we were able to easily generate estimators of population parameters and measures of goodness of fit.  Be sure to check out the source code at <https://github.com/jwindle/gmmfun>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eb5535-1f32-4142-a14b-6c8db02d3ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
